{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6eb755",
   "metadata": {},
   "source": [
    "## 4 Model Evaluation\n",
    "\n",
    "This notebook loads the Whisper medium model finetuned on 8 hours of Sursilvan data and evaluates it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6f5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jiwer import wer, cer\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import librosa\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "from constants import FOLDER_NAMES, DATA_ROOT\n",
    "from helpers import get_idiom_name_by_folder\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"./whisper-medium-rm-all\"  # Path to your fine-tuned model\n",
    "TEST_FILE = \"test.tsv\"\n",
    "CLIPS_DIR = \"clips\"\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_SAMPLES = None  # Set to a number for quick test, None for full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400a021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Whisper Romansh Model Evaluation\n",
      "============================================================\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "\n",
      "üì• Loading fine-tuned model from ./whisper-medium-rm-all...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963aa57034174974bf842f7fc34fe2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n",
      "Model parameters: 763.9M\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Check GPU and Load Model (Fixed)\n",
    "print(\"=\"*60)\n",
    "print(\"Whisper Romansh Model Evaluation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Load your fine-tuned model (Hugging Face format)\n",
    "print(f\"\\nüì• Loading fine-tuned model from {MODEL_PATH}...\")\n",
    "\n",
    "# Load processor (for feature extraction and tokenization)\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Load model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d332ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading test data from all idioms...\n",
      "\n",
      "üìÇ Processing rmsurmiran-cc-2021-12-23...\n",
      "  Added 151 samples from rmsurmiran-cc-2021-12-23\n",
      "\n",
      "üìÇ Processing rmsutsilv-cc-2022-05-18...\n",
      "  Added 94 samples from rmsutsilv-cc-2022-05-18\n",
      "\n",
      "üìÇ Processing rmputer-cc-2021-06-11...\n",
      "  Added 114 samples from rmputer-cc-2021-06-11\n",
      "\n",
      "üìÇ Processing rm-cc-2021-05-28...\n",
      "  Added 81 samples from rm-cc-2021-05-28\n",
      "\n",
      "üìÇ Processing rmvallader-cc-2021-05-28...\n",
      "  Added 97 samples from rmvallader-cc-2021-05-28\n",
      "\n",
      "üìÇ Processing rmsursilv-cc-2021-05-28...\n",
      "  Added 94 samples from rmsursilv-cc-2021-05-28\n",
      "\n",
      "============================================================\n",
      "üìä Combined Test Dataset Statistics\n",
      "============================================================\n",
      "Total test samples across all idioms: 631\n",
      "\n",
      "‚úÖ Total audio files to process: 631\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Test Data from All Idioms\n",
    "\n",
    "print(\"\\nüìÇ Loading test data from all idioms...\")\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "audio_paths = []\n",
    "references = []\n",
    "idioms = []\n",
    "\n",
    "for idiom_folder in FOLDER_NAMES:\n",
    "    idiom_path = os.path.join(DATA_ROOT, idiom_folder)\n",
    "    idiom_name = get_idiom_name_by_folder(idiom_folder)\n",
    "    test_tsv = os.path.join(idiom_path, \"test.tsv\")\n",
    "    clips_path = os.path.join(idiom_path, \"clips\")\n",
    "    \n",
    "    if not os.path.exists(test_tsv):\n",
    "        print(f\"‚ö†Ô∏è No test.tsv found for {idiom_folder}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nüìÇ Processing {idiom_folder}...\")\n",
    "    \n",
    "    df_idiom = pd.read_csv(test_tsv, sep='\\t')\n",
    "    \n",
    "    valid_indices = []\n",
    "    for idx, row in df_idiom.iterrows():\n",
    "        audio_path = os.path.join(clips_path, row['path'])\n",
    "        if os.path.exists(audio_path):\n",
    "            valid_indices.append(idx)\n",
    "            audio_paths.append(audio_path)\n",
    "            references.append(row['sentence'])\n",
    "            idioms.append(idiom_name)\n",
    "    \n",
    "    df_idiom_valid = df_idiom.loc[valid_indices].copy()\n",
    "    df_idiom_valid['idiom'] = idiom_folder\n",
    "    df_test = pd.concat([df_test, df_idiom_valid], ignore_index=True)\n",
    "    \n",
    "    print(f\"  Added {len(df_idiom_valid)} samples from {idiom_folder}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä Combined Test Dataset Statistics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total test samples across all idioms: {len(df_test)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total audio files to process: {len(audio_paths)}\")\n",
    "\n",
    "if NUM_SAMPLES:\n",
    "    df_test = df_test.head(NUM_SAMPLES)\n",
    "    audio_paths = audio_paths[:NUM_SAMPLES]\n",
    "    print(f\"Using first {NUM_SAMPLES} samples for quick test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257d94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéôÔ∏è Transcribing 631 test files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/79 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n",
      "Transcribing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [06:27<00:00,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transcribed 631 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Batch Transcription (Fixed)\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_paths, processor, device):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.processor = processor\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_paths[idx]\n",
    "        # Load audio\n",
    "        audio_array, sr = librosa.load(audio_path, sr=16000)\n",
    "        \n",
    "        # Process to features\n",
    "        input_features = self.processor(\n",
    "            audio_array, \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features[0]  # Remove batch dimension\n",
    "        \n",
    "        return input_features\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to handle different sized tensors\"\"\"\n",
    "    # Find max length in batch\n",
    "    max_len = max(features.shape[-1] for features in batch)\n",
    "    \n",
    "    # Pad all features to max length\n",
    "    padded_batch = []\n",
    "    for features in batch:\n",
    "        pad_len = max_len - features.shape[-1]\n",
    "        if pad_len > 0:\n",
    "            # Pad with zeros along the time dimension\n",
    "            padding = torch.zeros((features.shape[0], pad_len))\n",
    "            padded = torch.cat([features, padding], dim=-1)\n",
    "        else:\n",
    "            padded = features\n",
    "        padded_batch.append(padded)\n",
    "    \n",
    "    # Stack into batch\n",
    "    return torch.stack(padded_batch)\n",
    "\n",
    "print(f\"\\nüéôÔ∏è Transcribing {len(audio_paths)} test files...\")\n",
    "\n",
    "# Create dataset and dataloader with custom collate\n",
    "dataset = AudioDataset(audio_paths, processor, DEVICE)\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=8, \n",
    "    shuffle=False, \n",
    "    num_workers=0,  # Set to 0 to avoid multiprocessing issues\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "transcriptions = []\n",
    "\n",
    "for batch_features in tqdm(dataloader, desc=\"Transcribing\"):\n",
    "    # Move batch to device\n",
    "    batch_features = batch_features.to(DEVICE)\n",
    "    \n",
    "    # Generate transcriptions for the batch\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(\n",
    "            batch_features,\n",
    "            max_length=225,\n",
    "            num_beams=1,\n",
    "            task=\"transcribe\"\n",
    "        )\n",
    "    \n",
    "    # Decode batch\n",
    "    batch_transcriptions = processor.batch_decode(\n",
    "        predicted_ids, \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    transcriptions.extend(batch_transcriptions)\n",
    "\n",
    "print(f\"‚úÖ Transcribed {len(transcriptions)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2481eb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä FINAL RESULTS - PER IDIOM\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "üìà OVERALL RESULTS\n",
      "==================================================\n",
      "Total test samples: 631\n",
      "Valid pairs: 631/631\n",
      "\n",
      "Word Error Rate (WER): 0.0167 (1.67%)\n",
      "Character Error Rate (CER): 0.0071 (0.71%)\n",
      "\n",
      "==================================================\n",
      "üìä PER IDIOM RESULTS\n",
      "==================================================\n",
      "\n",
      "üìÅ SURMIRAN\n",
      "  Samples: 151\n",
      "  WER: 0.0127 (1.27%)\n",
      "  CER: 0.0048 (0.48%)\n",
      "\n",
      "üìÅ SUTSILVAN\n",
      "  Samples: 94\n",
      "  WER: 0.0063 (0.63%)\n",
      "  CER: 0.0033 (0.33%)\n",
      "\n",
      "üìÅ PUTER\n",
      "  Samples: 114\n",
      "  WER: 0.0061 (0.61%)\n",
      "  CER: 0.0025 (0.25%)\n",
      "\n",
      "üìÅ RG\n",
      "  Samples: 81\n",
      "  WER: 0.0343 (3.43%)\n",
      "  CER: 0.0188 (1.88%)\n",
      "\n",
      "üìÅ VALLADER\n",
      "  Samples: 97\n",
      "  WER: 0.0211 (2.11%)\n",
      "  CER: 0.0092 (0.92%)\n",
      "\n",
      "üìÅ SURSILVAN\n",
      "  Samples: 94\n",
      "  WER: 0.0217 (2.17%)\n",
      "  CER: 0.0042 (0.42%)\n",
      "\n",
      "==================================================\n",
      "üìã SUMMARY TABLE\n",
      "==================================================\n",
      "    idiom  samples      wer      cer\n",
      " Surmiran      151 0.012748 0.004806\n",
      "Sutsilvan       94 0.006293 0.003329\n",
      "    Puter      114 0.006132 0.002499\n",
      "       RG       81 0.034252 0.018803\n",
      " Vallader       97 0.021125 0.009180\n",
      "Sursilvan       94 0.021665 0.004220\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Calculate WER and CER per idiom\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL RESULTS - PER IDIOM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Group by idiom\n",
    "idiom_results = defaultdict(lambda: {\"references\": [], \"hypotheses\": []})\n",
    "\n",
    "# Filter valid pairs and group by idiom\n",
    "valid_pairs = []\n",
    "for ref, hyp, idiom in zip(references, transcriptions, idioms):\n",
    "    if ref and hyp:\n",
    "        valid_pairs.append((ref, hyp, idiom))\n",
    "        idiom_results[idiom][\"references\"].append(ref)\n",
    "        idiom_results[idiom][\"hypotheses\"].append(hyp)\n",
    "\n",
    "if not valid_pairs:\n",
    "    print(\"‚ùå No valid reference-hypothesis pairs found!\")\n",
    "else:\n",
    "    # Overall results\n",
    "    all_refs = [p[0] for p in valid_pairs]\n",
    "    all_hyps = [p[1] for p in valid_pairs]\n",
    "    \n",
    "    overall_wer = wer(all_refs, all_hyps)\n",
    "    overall_cer = cer(all_refs, all_hyps)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìà OVERALL RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total test samples: {len(df_test)}\")\n",
    "    print(f\"Valid pairs: {len(valid_pairs)}/{len(df_test)}\")\n",
    "    print(f\"\\nWord Error Rate (WER): {overall_wer:.4f} ({overall_wer*100:.2f}%)\")\n",
    "    print(f\"Character Error Rate (CER): {overall_cer:.4f} ({overall_cer*100:.2f}%)\")\n",
    "    \n",
    "    # Per-idiom results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä PER IDIOM RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Store results for dataframe\n",
    "    per_idiom_data = []\n",
    "    \n",
    "    for idiom, data in idiom_results.items():\n",
    "        if len(data[\"references\"]) > 0:\n",
    "            idiom_wer = wer(data[\"references\"], data[\"hypotheses\"])\n",
    "            idiom_cer = cer(data[\"references\"], data[\"hypotheses\"])\n",
    "            \n",
    "            print(f\"\\nüìÅ {idiom.upper()}\")\n",
    "            print(f\"  Samples: {len(data['references'])}\")\n",
    "            print(f\"  WER: {idiom_wer:.4f} ({idiom_wer*100:.2f}%)\")\n",
    "            print(f\"  CER: {idiom_cer:.4f} ({idiom_cer*100:.2f}%)\")\n",
    "            \n",
    "            per_idiom_data.append({\n",
    "                \"idiom\": idiom,\n",
    "                \"samples\": len(data[\"references\"]),\n",
    "                \"wer\": idiom_wer,\n",
    "                \"cer\": idiom_cer\n",
    "            })\n",
    "    \n",
    "    # Create summary dataframe\n",
    "    summary_df = pd.DataFrame(per_idiom_data)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìã SUMMARY TABLE\")\n",
    "    print(\"=\"*50)\n",
    "    print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d709a7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìù SAMPLE TRANSCRIPTIONS\n",
      "============================================================\n",
      "\n",
      "--- Sample 1 ---\n",
      "Reference: Noua sa mossa la donna?...\n",
      "Hypothesis: Noua sa mossa la donna?...\n",
      "Sample WER: 0.0000\n",
      "----------------------------------------\n",
      "\n",
      "--- Sample 2 ---\n",
      "Reference: La radunanza communala da Luzein ha approv√† il nov model da scola cun in lieu da scola communabel per la scolina e la scola primara a Pany. Quai a partir da l‚Äôonn da scola 2 1000 21 22.Er approv√† ha l...\n",
      "Hypothesis: La radunanza communala da Luzein ha approv√† il nov model da scola cun in lieu da scola communabel per la scolina e la scola primara a Pany. Quai a partir da l‚Äôonn da scola 2 1000 21 22.Er approv√† ha l...\n",
      "Sample WER: 0.0000\n",
      "----------------------------------------\n",
      "\n",
      "--- Sample 3 ---\n",
      "Reference: Chegl capeta darar....\n",
      "Hypothesis: Chegl capeta darar....\n",
      "Sample WER: 0.0000\n",
      "----------------------------------------\n",
      "\n",
      "--- Sample 4 ---\n",
      "Reference: E lura vegn que ad√ºna p√º concret, tuot es pront, uossa haun ils scienzios da la h. t. w. da strer vi dal glatsch. √ún glatsch chi'd es var 70 centimeters gross. La tensiun es granda e tar duos tonnas e...\n",
      "Hypothesis: E lura vegn que ad√ºna p√º concret, tuot es pront, uossa haun ils scienzios da la h. t. w. da strer vi dal glatsch. √ún glatsch chi'd es var 70 centimeters gross. La tensiun es granda e tar duos tonas e ...\n",
      "Sample WER: 0.0200\n",
      "----------------------------------------\n",
      "\n",
      "--- Sample 5 ---\n",
      "Reference: Ma scu cha vains g√ºsta udieu, cun √ºn derschalet es managio c√≤ √ºn nosch s√∂mmi cha nus tuots varegians gi√† gieu √ºna vouta. √ún s√∂mmi cun emoziuns negativas, cun temma u magari eir cun panica....\n",
      "Hypothesis: Ma scu cha vains g√ºsta udieu, cun √ºn derschalet es managio c√≤ √ºn nosch s√∂mmi cha nus tuots varegians gi√† gieu √ºna vouta. √ún s√∂mmi cun emoziuns negativas, cun temma u magari eir cun panica....\n",
      "Sample WER: 0.0000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Sample Transcriptions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìù SAMPLE TRANSCRIPTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show 5 random samples\n",
    "import random\n",
    "sample_indices = random.sample(range(len(valid_pairs)), min(5, len(valid_pairs)))\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Reference: {references[idx][:200]}...\")\n",
    "    print(f\"Hypothesis: {transcriptions[idx][:200]}...\")\n",
    "    \n",
    "    # Calculate sample-level WER\n",
    "    sample_wer = wer(references[idx], transcriptions[idx])\n",
    "    print(f\"Sample WER: {sample_wer:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TARS GPU)",
   "language": "python",
   "name": "tars_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
